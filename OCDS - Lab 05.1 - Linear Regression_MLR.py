# -*- coding: utf-8 -*-
"""OCDS - Lab 05.1 - Linear Regression_MLR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y2S1Pyl71prJIEzVfF7SQIb7hcGrJQTl

# Linear Regression_SLR ----------------------------
"""

#Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.api as sm

# Importing the dataset
dataset = pd.read_csv('/content/sample_data/kc_house_data.csv')
dataset.head()

dataset.isnull().sum()

# Linear Regression
from sklearn.linear_model import LinearRegression
reg = LinearRegression()

x = dataset[dataset.columns[5]] 
y = dataset[dataset.columns[2]] # Price

X = sm.add_constant(x)
est = sm.OLS(y, X).fit()
print(est.summary())

# predicting on X_test....This is a rare occasion to predict the TV using one IV
x_1 = dataset['sqft_living'].values.reshape(-1, 1)
y_1 = dataset['price'].values.reshape(-1, 1)
reg.fit(x_1, y_1)
y_pred = reg.predict(x_1)
y_pred.round(2)

from sklearn.metrics import r2_score
r2_score(y_1, y_pred).round(3)

from sklearn.metrics import mean_squared_error
print("Mean Squared Error: ", mean_squared_error(y_1, y_pred).round(2))

"""# **Linear Regression_MLR ----------------------------**"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.api as sm

# Importing the dataset
data = pd.read_csv('/content/sample_data/50_Startups.csv')
data.head()

data.shape

data.info()

data.isnull().sum()

data.describe()

data['State'].describe()

# Label Encoding ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Can use other encoding techniques such as Factorization or One Hot Encoding
import warnings
warnings.filterwarnings("ignore")

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
data['State'] = labelencoder.fit_transform(data['State'])
data.head()

X = data[data.columns[0:4]]
y = data[data.columns[4]]

# Linear Regression
from sklearn.linear_model import LinearRegression
Linear_Regression = LinearRegression()
Linear_Regression.fit(X, y)
Linear_Regression.score(X, y).round(2) # Return the R^2

print(Linear_Regression.coef_)
print(Linear_Regression.intercept_.round(2))

X2 = sm.add_constant(X)
est = sm.OLS(y, X2)
est2 = est.fit()
print(est2.summary())

# Predictions
predictions = Linear_Regression.predict(X)
predictions[0:2].round(2)

"""### **Build a Linear Regression predictive model**"""

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)

# training a linear regression model on train
Linear_Regression.fit(X_train,y_train)

# Accuracy of the model
#Train Accuracy
print('Train Accuracy = ', (Linear_Regression.score(X_train, y_train).round(2))*100,'%')
# Test Accuracy....This is the one we consider when evaluating the model
print('Test Accuracy = ', (Linear_Regression.score(X_test, y_test).round(2))*100,'%')

from sklearn.metrics import r2_score
r2_score(y_test, y_pred).round(3)

# predicting on X_test
y_pred = Linear_Regression.predict(X_test)
y_pred.round(2)

pd.DataFrame({'Actual': y_test.round(2), 'Predicted': y_pred.round(2)})

# evaluation using r-square
Linear_Regression.score(X_train,y_train).round(2)

# calculating MSE, RMSE, MAE
from sklearn.metrics import mean_squared_error, mean_absolute_error
print("Mean Squared Error: ", mean_squared_error(y_test, y_pred).round(2))
print('Mean Absolute Error: ', mean_absolute_error(y_test, y_pred).round(2))  
print('Root Mean Squared Error: ', np.sqrt(mean_squared_error(y_test, y_pred)).round(2))

X3 = sm.add_constant(X_train)
est = sm.OLS(y_train, X3)
est2 = est.fit()
print(est2.summary())

X_train

# training data plot
x_plot = plt.scatter(X_train['Marketing Spend'], y_train, c='r')
plt.hlines(y=0, xmin= -1, xmax=1)
plt.title('Training Data plot')
plt.xlabel('Marketing Spend')
plt.ylabel('Profit')

"""**Residuals Plot**

Residuals, in the context of regression models, are the difference between the observed value of the target variable (y_test) and the predicted value (y_pred), i.e. the error of the prediction.

**Residual = Observed â€“ Predicted**
"""

# residual plot
x_plot = plt.scatter(y_test, (y_test - y_pred), c='b')
plt.hlines(y=0, xmin= -1, xmax=1)
plt.title('Residual plot')
plt.xlabel('y_test')
plt.ylabel('Residuals')

"""**Using Yellow Brick library**"""

# pip install yellowbrick
from yellowbrick.regressor import ResidualsPlot

visualizer = ResidualsPlot(Linear_Regression)

visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer
visualizer.score(X_test, y_test)  # Evaluate the model on the test data
visualizer.show()